{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946d9959-e1c1-4ce1-a755-80ece148d32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "STARTING BATCH EXECUTION: 100 Runs\n",
      "Target Size: 16 | Alpha: 0.9997 | Initial T: 5.0\n",
      "==================================================\n",
      "Completed 10/100 runs...\n",
      "Completed 20/100 runs...\n",
      "Completed 30/100 runs...\n",
      "Completed 40/100 runs...\n",
      "Completed 50/100 runs...\n",
      "Completed 60/100 runs...\n",
      "Completed 70/100 runs...\n",
      "Completed 80/100 runs...\n",
      "Completed 90/100 runs...\n",
      "Completed 100/100 runs...\n",
      "\n",
      "##################################################\n",
      "FINAL STATISTICS & ANALYSIS\n",
      "##################################################\n",
      "Success Rate: 57.00%\n",
      "Avg Runtime: 1.6083s (StdDev: 0.9143s)\n",
      "Max Size Found: 16\n",
      "Avg Size Found: 14.34\n",
      "------------------------------\n",
      "DIVERSIFICATION ANALYSIS\n",
      "Unique Cliques Found: 97\n",
      "Total Unique Nodes Involved: 256 / 256\n",
      "Exploration Coverage: 100.00%\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "class HammingBatchAnalyzer:\n",
    "    def __init__(self, nam_file):\n",
    "        with open(nam_file, 'rb') as f:\n",
    "            self.codes_int = pickle.load(f)\n",
    "        self.num_nodes = len(self.codes_int) - 1\n",
    "\n",
    "    def are_neighbors(self, u: int, v: int) -> bool:\n",
    "        if u == v: return False\n",
    "        if u > v: u, v = v, u\n",
    "        return ((self.codes_int[u] >> v) & 1) == 0\n",
    "\n",
    "    def get_conflicts(self, S):\n",
    "        count = 0\n",
    "        for i in range(len(S)):\n",
    "            for j in range(i + 1, len(S)):\n",
    "                if not self.are_neighbors(S[i], S[j]):\n",
    "                    count += 1\n",
    "        return count\n",
    "\n",
    "    def run_single_solve(self, run_id, target=16, max_iter=50000):\n",
    "        # Parameters (Printing as requested)\n",
    "        T = 5.0\n",
    "        T_min = 0.0001\n",
    "        alpha = 0.9997 \n",
    "        penalty_factor = 2.0\n",
    "        \n",
    "        v_self = random.randint(1, self.num_nodes)\n",
    "        neighbors = [i for i in range(1, self.num_nodes + 1) if i != v_self and self.are_neighbors(v_self, i)]\n",
    "        random.shuffle(neighbors)\n",
    "        S = [v_self] + neighbors[:10] \n",
    "        \n",
    "        current_conflicts = self.get_conflicts(S)\n",
    "        best_size = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for i in range(max_iter):\n",
    "            if T <= T_min: break\n",
    "            \n",
    "            new_S = list(S)\n",
    "            rand_val = random.random()\n",
    "            \n",
    "            # Neighborhood Moves\n",
    "            if rand_val < 0.3 and len(new_S) > 1:\n",
    "                node_to_remove = random.choice([u for u in new_S if u != v_self])\n",
    "                new_S.remove(node_to_remove)\n",
    "            elif rand_val < 0.6:\n",
    "                potential = [n for n in range(1, self.num_nodes + 1) if n not in new_S]\n",
    "                if potential: new_S.append(random.choice(potential))\n",
    "            else:\n",
    "                if len(new_S) > 1:\n",
    "                    node_to_remove = random.choice([u for u in new_S if u != v_self])\n",
    "                    new_S.remove(node_to_remove)\n",
    "                    potential = [n for n in range(1, self.num_nodes + 1) if n not in new_S]\n",
    "                    if potential: new_S.append(random.choice(potential))\n",
    "\n",
    "            new_conflicts = self.get_conflicts(new_S)\n",
    "            delta_energy = (new_conflicts - current_conflicts) * penalty_factor - (len(new_S) - len(S))\n",
    "\n",
    "            if delta_energy < 0 or random.random() < math.exp(-delta_energy / T):\n",
    "                S = new_S\n",
    "                current_conflicts = new_conflicts\n",
    "            \n",
    "            if current_conflicts == 0:\n",
    "                if len(S) > best_size:\n",
    "                    best_size = len(S)\n",
    "                if best_size >= target:\n",
    "                    break\n",
    "            T *= alpha \n",
    "\n",
    "        end_time = time.time()\n",
    "        return {\n",
    "            \"success\": best_size >= target,\n",
    "            \"size\": best_size,\n",
    "            \"time\": end_time - start_time,\n",
    "            \"clique\": tuple(sorted(S)) if current_conflicts == 0 else None\n",
    "        }\n",
    "\n",
    "    def batch_execute(self, num_runs=100, target=16):\n",
    "        print(\"=\"*50)\n",
    "        print(f\"STARTING BATCH EXECUTION: {num_runs} Runs\")\n",
    "        print(f\"Target Size: {target} | Alpha: 0.9997 | Initial T: 5.0\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        results = []\n",
    "        for r in range(1, num_runs + 1):\n",
    "            res = self.run_single_solve(r, target)\n",
    "            results.append(res)\n",
    "            if r % 10 == 0:\n",
    "                print(f\"Completed {r}/{num_runs} runs...\")\n",
    "\n",
    "        # Statistics Calculation\n",
    "        times = [r['time'] for r in results]\n",
    "        sizes = [r['size'] for r in results]\n",
    "        successes = [r['success'] for r in results]\n",
    "        unique_cliques = set([r['clique'] for r in results if r['clique'] is not None])\n",
    "        \n",
    "        # Diversification: All unique nodes found across all valid cliques\n",
    "        all_nodes = set()\n",
    "        for c in unique_cliques:\n",
    "            all_nodes.update(c)\n",
    "\n",
    "        print(\"\\n\" + \"#\"*50)\n",
    "        print(\"FINAL STATISTICS & ANALYSIS\")\n",
    "        print(\"#\"*50)\n",
    "        print(f\"Success Rate: {(sum(successes)/num_runs)*100:.2f}%\")\n",
    "        print(f\"Avg Runtime: {statistics.mean(times):.4f}s (StdDev: {statistics.stdev(times):.4f}s)\")\n",
    "        print(f\"Max Size Found: {max(sizes)}\")\n",
    "        print(f\"Avg Size Found: {statistics.mean(sizes):.2f}\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"DIVERSIFICATION ANALYSIS\")\n",
    "        print(f\"Unique Cliques Found: {len(unique_cliques)}\")\n",
    "        print(f\"Total Unique Nodes Involved: {len(all_nodes)} / {self.num_nodes}\")\n",
    "        print(f\"Exploration Coverage: {(len(all_nodes)/self.num_nodes)*100:.2f}%\")\n",
    "        print(\"#\"*50)\n",
    "\n",
    "# --- Run Analysis ---\n",
    "analyzer = HammingBatchAnalyzer('hamming8-4_nam.data')\n",
    "analyzer.batch_execute(num_runs=100, target=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d3ad8c-5c2e-4e23-8142-b1ff525ffccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Test: 100 Runs on Hamming 8-4 (Target 16)\n",
      "\n",
      "========================================\n",
      "SUCCESS RATE: 95.00%\n",
      "AVG TIME: 0.3863s\n",
      "STDEV: 0.3590s\n",
      "UNIQUE CLIQUES: 85\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "class TunedHammingSA:\n",
    "    def __init__(self, nam_file):\n",
    "        with open(nam_file, 'rb') as f:\n",
    "            self.codes_int = pickle.load(f)\n",
    "        self.num_nodes = len(self.codes_int) - 1\n",
    "\n",
    "    def are_neighbors(self, u: int, v: int) -> bool:\n",
    "        if u == v: return False\n",
    "        if u > v: u, v = v, u\n",
    "        return ((self.codes_int[u] >> v) & 1) == 0\n",
    "\n",
    "    def run_solve(self, target=16):\n",
    "        # --- HYPER-PARAMETERS ---\n",
    "        T = 2.5            # Slightly higher starting T for better initial mixing\n",
    "        alpha = 0.9992     # Slightly faster cooling than before to avoid plateau idling\n",
    "        max_iter = 40000\n",
    "        pool_size = 8      # Increased pool size for better \"Min-Conflict\" selection\n",
    "        \n",
    "        nodes = list(range(1, self.num_nodes + 1))\n",
    "        S = random.sample(nodes, 10) # Start with 10 random nodes\n",
    "        \n",
    "        best_size = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for step in range(max_iter):\n",
    "            if T < 0.00001: break\n",
    "            \n",
    "            # --- TUNED VIBRATION ---\n",
    "            # High penalty for 85 steps, Low penalty for 15 steps\n",
    "            penalty = 25.0 if (step % 100 < 85) else 3.5\n",
    "            \n",
    "            # 1. EVICITION: Identify node in S with most conflicts\n",
    "            # (Local conflict check is faster than global)\n",
    "            u = max(S, key=lambda z: sum(1 for m in S if z != m and not self.are_neighbors(z, m)))\n",
    "            \n",
    "            # 2. TUNED SELECTION: Min-Conflict from a larger pool\n",
    "            pool = random.sample(nodes, pool_size)\n",
    "            v = min(pool, key=lambda z: sum(1 for m in S if z != u and not self.are_neighbors(z, m)))\n",
    "            \n",
    "            # 3. CALCULATE DELTA\n",
    "            curr_conflicts = sum(1 for i in range(len(S)) for j in range(i+1, len(S)) if not self.are_neighbors(S[i], S[j]))\n",
    "            S_next = [n for n in S if n != u] + [v]\n",
    "            next_conflicts = sum(1 for i in range(len(S_next)) for j in range(i+1, len(S_next)) if not self.are_neighbors(S_next[i], S_next[j]))\n",
    "            \n",
    "            # Energy Delta\n",
    "            e_old = (curr_conflicts * penalty) - len(S)\n",
    "            e_new = (next_conflicts * penalty) - len(S_next)\n",
    "            delta_e = e_new - e_old\n",
    "\n",
    "            # 4. METROPOLIS\n",
    "            if delta_e <= 0 or random.random() < math.exp(-delta_e / T):\n",
    "                S = S_next\n",
    "                curr_conflicts = next_conflicts\n",
    "            \n",
    "            # 5. GROWTH & SUCCESS\n",
    "            if curr_conflicts == 0:\n",
    "                # Greedy Expansion\n",
    "                for cand in nodes:\n",
    "                    if cand not in S and all(self.are_neighbors(cand, m) for m in S):\n",
    "                        S.append(cand)\n",
    "                \n",
    "                best_size = len(S)\n",
    "                if best_size >= target:\n",
    "                    return True, time.time() - start_time, tuple(sorted(S))\n",
    "\n",
    "            T *= alpha \n",
    "        \n",
    "        return False, time.time() - start_time, None\n",
    "\n",
    "    def batch_test(self, num_runs=100):\n",
    "        print(f\"Tuning Test: 100 Runs on Hamming 8-4 (Target 16)\")\n",
    "        results = [self.run_solve() for _ in range(num_runs)]\n",
    "        \n",
    "        successes = [r for r in results if r[0]]\n",
    "        times = [r[1] for r in successes]\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(f\"SUCCESS RATE: {(len(successes)/num_runs)*100:.2f}%\")\n",
    "        if successes:\n",
    "            print(f\"AVG TIME: {statistics.mean(times):.4f}s\")\n",
    "            print(f\"STDEV: {statistics.stdev(times):.4f}s\")\n",
    "            print(f\"UNIQUE CLIQUES: {len(set(r[2] for r in successes))}\")\n",
    "        print(\"=\"*40)\n",
    "\n",
    "# Execute\n",
    "tester = TunedHammingSA('hamming8-4_nam.data')\n",
    "tester.batch_test(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68cff978-e2d9-491d-9dba-5ea41fdad8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Running C125-9 (Target 34) | Baseline Algorithm 3\n",
      "Completed 10/100...\n",
      "Completed 20/100...\n",
      "Completed 30/100...\n",
      "Completed 40/100...\n",
      "Completed 50/100...\n",
      "Completed 60/100...\n",
      "Completed 70/100...\n",
      "Completed 80/100...\n",
      "Completed 90/100...\n",
      "Completed 100/100...\n",
      "\n",
      "########################################\n",
      "BASELINE RESULTS: C125-9\n",
      "########################################\n",
      "Success Rate: 100%\n",
      "Avg Time (Success): 1.5997s\n",
      "Unique Cliques Found (Size >= 30): 97\n",
      "Exploration Coverage: 49.60%\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "class MaximumCliqueBatchTester:\n",
    "    def __init__(self, nam_file):\n",
    "        with open(nam_file, 'rb') as f:\n",
    "            self.codes_int = pickle.load(f)\n",
    "        self.num_nodes = len(self.codes_int) - 1\n",
    "\n",
    "    def are_neighbors(self, u: int, v: int) -> bool:\n",
    "        if u == v: return False\n",
    "        return ((self.codes_int[u] >> v) & 1) == 0\n",
    "\n",
    "    def get_node_conflicts(self, node, S):\n",
    "        return sum(1 for member in S if not self.are_neighbors(node, member))\n",
    "\n",
    "    def calculate_total_conflicts(self, S):\n",
    "        conflicts = 0\n",
    "        for i in range(len(S)):\n",
    "            for j in range(i + 1, len(S)):\n",
    "                if not self.are_neighbors(S[i], S[j]):\n",
    "                    conflicts += 1\n",
    "        return conflicts\n",
    "\n",
    "    def solve_single(self, target=34, max_iter=200000):\n",
    "        # Algorithm 3: Uniform start + No Penalty Oscillation\n",
    "        seed_node = random.randint(1, self.num_nodes)\n",
    "        S = [seed_node]\n",
    "        all_nodes = list(range(1, self.num_nodes + 1))\n",
    "        random.shuffle(all_nodes)\n",
    "        for n in all_nodes:\n",
    "            if n not in S and all(self.are_neighbors(n, member) for member in S):\n",
    "                S.append(n)\n",
    "        \n",
    "        current_conflicts = 0\n",
    "        T = 2.0\n",
    "        alpha = 0.99995  # Slow cooling\n",
    "        penalty_weight = 10.0 # Static Penalty\n",
    "        \n",
    "        start_t = time.time()\n",
    "        for i in range(max_iter):\n",
    "            if T < 0.001: break\n",
    "            \n",
    "            new_S = list(S)\n",
    "            move_type = random.random()\n",
    "            if move_type < 0.2 and len(new_S) > 1:\n",
    "                new_S.remove(random.choice(new_S))\n",
    "            elif move_type < 0.7:\n",
    "                candidates = random.sample(range(1, self.num_nodes + 1), 15)\n",
    "                best_cand = min(candidates, key=lambda n: self.get_node_conflicts(n, new_S))\n",
    "                if best_cand not in new_S: new_S.append(best_cand)\n",
    "            else:\n",
    "                if len(new_S) > 1:\n",
    "                    new_S.remove(random.choice(new_S))\n",
    "                    candidates = random.sample(range(1, self.num_nodes + 1), 15)\n",
    "                    best_cand = min(candidates, key=lambda n: self.get_node_conflicts(n, new_S))\n",
    "                    if best_cand not in new_S: new_S.append(best_cand)\n",
    "\n",
    "            new_conflicts = self.calculate_total_conflicts(new_S)\n",
    "            delta = (new_conflicts * penalty_weight - len(new_S)) - (current_conflicts * penalty_weight - len(S))\n",
    "\n",
    "            if delta < 0 or random.random() < math.exp(-delta / T):\n",
    "                S = new_S\n",
    "                current_conflicts = new_conflicts\n",
    "            \n",
    "            if current_conflicts == 0 and len(S) >= target:\n",
    "                return True, len(S), time.time() - start_t, tuple(sorted(S))\n",
    "            \n",
    "            T *= alpha\n",
    "        return False, len(S), time.time() - start_t, tuple(sorted(S)) if current_conflicts == 0 else None\n",
    "\n",
    "    def run_batch(self, num_runs=100):\n",
    "        print(f\"Batch Running C125-9 (Target 34) | Baseline Algorithm 3\")\n",
    "        results = []\n",
    "        for i in range(num_runs):\n",
    "            results.append(self.solve_single())\n",
    "            if (i+1) % 10 == 0: print(f\"Completed {i+1}/100...\")\n",
    "\n",
    "        successes = [r for r in results if r[0]]\n",
    "        times = [r[2] for r in successes]\n",
    "        unique_cliques = set([r[3] for r in results if r[3] is not None and r[1] >= 30])\n",
    "        all_nodes_found = set().union(*[set(c) for c in unique_cliques])\n",
    "\n",
    "        print(\"\\n\" + \"#\"*40)\n",
    "        print(\"BASELINE RESULTS: C125-9\")\n",
    "        print(\"#\"*40)\n",
    "        print(f\"Success Rate: {len(successes)}%\")\n",
    "        print(f\"Avg Time (Success): {statistics.mean(times) if times else 0:.4f}s\")\n",
    "        print(f\"Unique Cliques Found (Size >= 30): {len(unique_cliques)}\")\n",
    "        print(f\"Exploration Coverage: {(len(all_nodes_found)/self.num_nodes)*100:.2f}%\")\n",
    "        print(\"#\"*40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tester = MaximumCliqueBatchTester('C125-9_nam.data')\n",
    "    tester.run_batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42467b63-c59f-43c1-a109-27ea3d7889fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Running C125-9 | Algorithm 4 (PageRank + Oscillation)\n",
      "\n",
      "========================================\n",
      "ALGORITHM 4 FINAL BATCH RESULTS\n",
      "========================================\n",
      "Success Rate: 96%\n",
      "Avg Success Time: 8.5415s\n",
      "Unique Max Cliques Found: 91\n",
      "Structural Coverage: 50.40%\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import statistics\n",
    "import networkx as nx\n",
    "\n",
    "class Algorithm4BatchTester:\n",
    "    def __init__(self, nam_file):\n",
    "        with open(nam_file, 'rb') as f:\n",
    "            self.codes_int = pickle.load(f)\n",
    "        self.num_nodes = len(self.codes_int) - 1\n",
    "        self.weights = self._precompute_weights()\n",
    "\n",
    "    def are_neighbors(self, u, v):\n",
    "        if u == v: return False\n",
    "        return ((self.codes_int[u] >> v) & 1) == 0\n",
    "\n",
    "    def _precompute_weights(self):\n",
    "        G = nx.Graph()\n",
    "        for u in range(1, self.num_nodes + 1):\n",
    "            for v in range(u + 1, self.num_nodes + 1):\n",
    "                if self.are_neighbors(u, v): G.add_edge(u, v)\n",
    "        pr = nx.pagerank(G, alpha=0.85)\n",
    "        return [pr.get(i, 0)**3 for i in range(self.num_nodes + 1)]\n",
    "\n",
    "    def run_single(self, target=34, max_iter=100000):\n",
    "        nodes = list(range(1, self.num_nodes + 1))\n",
    "        w_sum = sum(self.weights[1:])\n",
    "        norm_weights = [w / w_sum for w in self.weights[1:]]\n",
    "        \n",
    "        # PR-Biased Initial State\n",
    "        S = random.choices(nodes, weights=norm_weights, k=15)\n",
    "        T, alpha = 2.0, 0.9999\n",
    "        start_t = time.time()\n",
    "\n",
    "        for step in range(max_iter):\n",
    "            if T < 0.001: break\n",
    "            penalty = 25.0 if (step % 100 < 85) else 3.5 # Oscillation\n",
    "            \n",
    "            # Min-Conflict / PR-Pool Logic\n",
    "            u = max(S, key=lambda z: sum(1 for m in S if z != m and not self.are_neighbors(z, m)))\n",
    "            pool = random.choices(nodes, weights=norm_weights, k=10)\n",
    "            v = min(pool, key=lambda z: sum(1 for m in S if z != u and not self.are_neighbors(z, m)))\n",
    "            \n",
    "            # Energy Calculation\n",
    "            curr_c = sum(1 for i in range(len(S)) for j in range(i+1, len(S)) if not self.are_neighbors(S[i], S[j]))\n",
    "            S_next = [n for n in S if n != u] + [v]\n",
    "            next_c = sum(1 for i in range(len(S_next)) for j in range(i+1, len(S_next)) if not self.are_neighbors(S_next[i], S_next[j]))\n",
    "            \n",
    "            delta = (next_c * penalty - len(S_next)) - (curr_c * penalty - len(S))\n",
    "            if delta <= 0 or random.random() < math.exp(-delta / T):\n",
    "                S, curr_c = S_next, next_c\n",
    "            \n",
    "            if curr_c == 0:\n",
    "                for cand in nodes:\n",
    "                    if cand not in S and all(self.are_neighbors(cand, m) for m in S): S.append(cand)\n",
    "                if len(S) >= target: return True, len(S), time.time() - start_t, tuple(sorted(S))\n",
    "            T *= alpha\n",
    "        return False, len(S), time.time() - start_t, None\n",
    "\n",
    "    def execute_batch(self, num_runs=100):\n",
    "        print(f\"Batch Running C125-9 | Algorithm 4 (PageRank + Oscillation)\")\n",
    "        results = [self.run_single() for _ in range(num_runs)]\n",
    "        successes = [r for r in results if r[0]]\n",
    "        times = [r[2] for r in successes]\n",
    "        unique_cliques = set([r[3] for r in results if r[3] is not None])\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(\"ALGORITHM 4 FINAL BATCH RESULTS\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"Success Rate: {len(successes)}%\")\n",
    "        print(f\"Avg Success Time: {statistics.mean(times):.4f}s\")\n",
    "        print(f\"Unique Max Cliques Found: {len(unique_cliques)}\")\n",
    "        print(f\"Structural Coverage: {(len(set().union(*[set(c) for c in unique_cliques]))/self.num_nodes)*100:.2f}%\")\n",
    "        print(\"=\"*40)\n",
    "\n",
    "tester = Algorithm4BatchTester('C125-9_nam.data')\n",
    "tester.execute_batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ccb3f91-f364-4c04-b6c5-eb959774f1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH RUN: Brock200_2 (Target 12) | 100 Runs\n",
      "Progress: 10/100\n",
      "Progress: 20/100\n",
      "Progress: 30/100\n",
      "Progress: 40/100\n",
      "Progress: 50/100\n",
      "Progress: 60/100\n",
      "Progress: 70/100\n",
      "Progress: 80/100\n",
      "Progress: 90/100\n",
      "Progress: 100/100\n",
      "\n",
      "########################################\n",
      "ALGORITHM 4.1 BATCH RESULTS\n",
      "########################################\n",
      "Success Rate: 0%\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from collections import deque\n",
    "import networkx as nx\n",
    "import statistics\n",
    "\n",
    "class BrockBatchTester:\n",
    "    def __init__(self, nam_file):\n",
    "        with open(nam_file, 'rb') as f:\n",
    "            self.codes_int = pickle.load(f)\n",
    "        self.num_nodes = len(self.codes_int) - 1\n",
    "        \n",
    "        # Spectral Analysis\n",
    "        G = nx.Graph()\n",
    "        for u in range(1, self.num_nodes + 1):\n",
    "            for v in range(u + 1, self.num_nodes + 1):\n",
    "                if ((self.codes_int[u] >> v) & 1) == 0:\n",
    "                    G.add_edge(u, v)\n",
    "        \n",
    "        pr_scores = nx.pagerank(G, alpha=0.85)\n",
    "        self.nodes_list = list(range(1, self.num_nodes + 1))\n",
    "        # PR^3 for high-density focus\n",
    "        self.weights = [pr_scores.get(i, 0)**3 for i in self.nodes_list]\n",
    "\n",
    "    def are_neighbors(self, u, v):\n",
    "        return ((self.codes_int[u] >> v) & 1) == 0\n",
    "\n",
    "    def get_node_conflicts(self, node, S):\n",
    "        return sum(1 for member in S if not self.are_neighbors(node, member))\n",
    "\n",
    "    def solve_once(self, target=12, max_steps=40000):\n",
    "        S = random.choices(self.nodes_list, weights=self.weights, k=1)\n",
    "        tabu = deque(maxlen=55)\n",
    "        T, alpha = 2.0, 0.99995\n",
    "        current_conflicts = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i in range(max_steps):\n",
    "            # Penalty Oscillation (Thermodynamic Vibration)\n",
    "            penalty = 22.0 if (i // 1000) % 2 == 0 else 4.0\n",
    "            \n",
    "            # --- CLOSE-OUT SCAN (Deterministic completion) ---\n",
    "            if len(S) == target - 1 and current_conflicts == 0:\n",
    "                for candidate in range(1, self.num_nodes + 1):\n",
    "                    if candidate not in S and self.get_node_conflicts(candidate, S) == 0:\n",
    "                        S.append(candidate)\n",
    "                        return True, len(S), time.time() - start_time, tuple(sorted(S))\n",
    "\n",
    "            new_S = list(S)\n",
    "            move = random.random()\n",
    "\n",
    "            if move < 0.12 and len(new_S) > 1: # Remove\n",
    "                node = random.choice(new_S)\n",
    "                new_S.remove(node)\n",
    "                tabu.append(node)\n",
    "            elif move < 0.55: # PR-Biased Add\n",
    "                potential = random.choices(self.nodes_list, weights=self.weights, k=70)\n",
    "                candidates = [n for n in potential if n not in tabu and n not in new_S]\n",
    "                if candidates:\n",
    "                    best_cand = min(candidates, key=lambda n: self.get_node_conflicts(n, new_S))\n",
    "                    new_S.append(best_cand)\n",
    "            else: # PR-Biased Swap\n",
    "                if len(new_S) > 1:\n",
    "                    rem = random.choice(new_S)\n",
    "                    new_S.remove(rem)\n",
    "                    tabu.append(rem)\n",
    "                    potential = random.choices(self.nodes_list, weights=self.weights, k=70)\n",
    "                    candidates = [n for n in potential if n not in tabu and n not in new_S]\n",
    "                    if candidates:\n",
    "                        add = min(candidates, key=lambda n: self.get_node_conflicts(n, new_S))\n",
    "                        new_S.append(add)\n",
    "\n",
    "            # Energy Logic\n",
    "            new_conf = sum(self.get_node_conflicts(new_S[j], new_S[j+1:]) for j in range(len(new_S)))\n",
    "            delta = (new_conf * penalty - len(new_S)) - (current_conflicts * penalty - len(S))\n",
    "\n",
    "            if delta < 0 or random.random() < math.exp(-delta / T):\n",
    "                S = new_S\n",
    "                current_conflicts = new_conf\n",
    "            \n",
    "            T *= alpha\n",
    "            if T < 0.02: break\n",
    "\n",
    "        return False, len(S), time.time() - start_time, None\n",
    "\n",
    "    def batch_run(self, num_runs=100, target=12):\n",
    "        print(f\"BATCH RUN: Brock200_2 (Target {target}) | 100 Runs\")\n",
    "        results = []\n",
    "        for i in range(num_runs):\n",
    "            res = self.solve_once(target)\n",
    "            results.append(res)\n",
    "            if (i+1) % 10 == 0: print(f\"Progress: {i+1}/100\")\n",
    "\n",
    "        successes = [r for r in results if r[0]]\n",
    "        times = [r[2] for r in successes]\n",
    "        unique_cliques = set([r[3] for r in results if r[3] is not None])\n",
    "        \n",
    "        print(\"\\n\" + \"#\"*40)\n",
    "        print(\"ALGORITHM 4.1 BATCH RESULTS\")\n",
    "        print(\"#\"*40)\n",
    "        print(f\"Success Rate: {len(successes)}%\")\n",
    "        if successes:\n",
    "            print(f\"Avg Solve Time: {statistics.mean(times):.4f}s\")\n",
    "            print(f\"Unique Max Cliques Found: {len(unique_cliques)}\")\n",
    "            all_nodes = set().union(*[set(c) for c in unique_cliques])\n",
    "            print(f\"Spectral Coverage: {(len(all_nodes)/self.num_nodes)*100:.2f}%\")\n",
    "        print(\"#\"*40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tester = BrockBatchTester('brock200_2_nam.data')\n",
    "    tester.batch_run(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ddc592-7608-4dba-a371-3291e057d24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BATCH EVALUATION: 10 FULL SUCCESSES ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 114\u001b[0m\n\u001b[0;32m    112\u001b[0m tester \u001b[38;5;241m=\u001b[39m BrockBatchRefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrock200_2_nam.data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Use 10 samples instead of 100 because Brock takes ~120s per success\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m tester\u001b[38;5;241m.\u001b[39mrun_batch(num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 98\u001b[0m, in \u001b[0;36mBrockBatchRefined.run_batch\u001b[1;34m(self, num_samples, target)\u001b[0m\n\u001b[0;32m     95\u001b[0m times, attempt_counts \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples):\n\u001b[1;32m---> 98\u001b[0m     duration, atts, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute_global_run(target)\n\u001b[0;32m     99\u001b[0m     times\u001b[38;5;241m.\u001b[39mappend(duration)\n\u001b[0;32m    100\u001b[0m     attempt_counts\u001b[38;5;241m.\u001b[39mappend(atts)\n",
      "Cell \u001b[1;32mIn[1], line 89\u001b[0m, in \u001b[0;36mBrockBatchRefined.execute_global_run\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m     attempts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 89\u001b[0m     success, best, clique \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolve_attempt(target, \u001b[38;5;241m40000\u001b[39m)\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start, attempts, clique\n",
      "Cell \u001b[1;32mIn[1], line 60\u001b[0m, in \u001b[0;36mBrockBatchRefined.solve_attempt\u001b[1;34m(self, target, max_steps)\u001b[0m\n\u001b[0;32m     58\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m potential \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tabu \u001b[38;5;129;01mand\u001b[39;00m n \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m new_S]\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m candidates:\n\u001b[1;32m---> 60\u001b[0m         best_cand \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(candidates, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m n: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_node_conflicts(n, new_S))\n\u001b[0;32m     61\u001b[0m         new_S\u001b[38;5;241m.\u001b[39mappend(best_cand)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# Swap\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 60\u001b[0m, in \u001b[0;36mBrockBatchRefined.solve_attempt.<locals>.<lambda>\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m     58\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m potential \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tabu \u001b[38;5;129;01mand\u001b[39;00m n \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m new_S]\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m candidates:\n\u001b[1;32m---> 60\u001b[0m         best_cand \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(candidates, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m n: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_node_conflicts(n, new_S))\n\u001b[0;32m     61\u001b[0m         new_S\u001b[38;5;241m.\u001b[39mappend(best_cand)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# Swap\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 29\u001b[0m, in \u001b[0;36mBrockBatchRefined.get_node_conflicts\u001b[1;34m(self, node, S)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mare_neighbors\u001b[39m(\u001b[38;5;28mself\u001b[39m, u, v):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodes_int[u] \u001b[38;5;241m>>\u001b[39m v) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_node_conflicts\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, S):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m member \u001b[38;5;129;01min\u001b[39;00m S \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mare_neighbors(node, member))\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msolve_attempt\u001b[39m(\u001b[38;5;28mself\u001b[39m, target, max_steps):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from collections import deque\n",
    "import networkx as nx\n",
    "import statistics\n",
    "\n",
    "class BrockBatchRefined:\n",
    "    def __init__(self, nam_file):\n",
    "        with open(nam_file, 'rb') as f:\n",
    "            self.codes_int = pickle.load(f)\n",
    "        self.num_nodes = len(self.codes_int) - 1\n",
    "        \n",
    "        # Spectral Analysis (Keep the PageRank bias)\n",
    "        G = nx.Graph()\n",
    "        for u in range(1, self.num_nodes + 1):\n",
    "            for v in range(u + 1, self.num_nodes + 1):\n",
    "                if ((self.codes_int[u] >> v) & 1) == 0:\n",
    "                    G.add_edge(u, v)\n",
    "        \n",
    "        pr_scores = nx.pagerank(G, alpha=0.85)\n",
    "        self.nodes_list = list(range(1, self.num_nodes + 1))\n",
    "        self.weights = [pr_scores.get(i, 0)**3 for i in self.nodes_list]\n",
    "\n",
    "    def are_neighbors(self, u, v):\n",
    "        return ((self.codes_int[u] >> v) & 1) == 0\n",
    "\n",
    "    def get_node_conflicts(self, node, S):\n",
    "        return sum(1 for member in S if not self.are_neighbors(node, member))\n",
    "\n",
    "    def solve_attempt(self, target, max_steps):\n",
    "        \"\"\"A single SA shot. Returns (Success, BestSize, Clique)\"\"\"\n",
    "        S = random.choices(self.nodes_list, weights=self.weights, k=1)\n",
    "        tabu = deque(maxlen=55)\n",
    "        T, alpha = 2.0, 0.99995\n",
    "        current_conflicts = 0\n",
    "        local_best = 1\n",
    "        \n",
    "        for i in range(max_steps):\n",
    "            penalty = 22.0 if (i // 1000) % 2 == 0 else 4.0\n",
    "            \n",
    "            # Close-out scan\n",
    "            if len(S) == target - 1 and current_conflicts == 0:\n",
    "                for candidate in self.nodes_list:\n",
    "                    if candidate not in S and self.get_node_conflicts(candidate, S) == 0:\n",
    "                        S.append(candidate)\n",
    "                        return True, len(S), tuple(sorted(S))\n",
    "\n",
    "            new_S = list(S)\n",
    "            move = random.random()\n",
    "            if move < 0.12 and len(new_S) > 1: # Remove\n",
    "                node = random.choice(new_S)\n",
    "                new_S.remove(node)\n",
    "                tabu.append(node)\n",
    "            elif move < 0.55: # Add\n",
    "                potential = random.choices(self.nodes_list, weights=self.weights, k=70)\n",
    "                candidates = [n for n in potential if n not in tabu and n not in new_S]\n",
    "                if candidates:\n",
    "                    best_cand = min(candidates, key=lambda n: self.get_node_conflicts(n, new_S))\n",
    "                    new_S.append(best_cand)\n",
    "            else: # Swap\n",
    "                if len(new_S) > 1:\n",
    "                    rem = random.choice(new_S)\n",
    "                    new_S.remove(rem)\n",
    "                    tabu.append(rem)\n",
    "                    potential = random.choices(self.nodes_list, weights=self.weights, k=70)\n",
    "                    candidates = [n for n in potential if n not in tabu and n not in new_S]\n",
    "                    if candidates:\n",
    "                        add = min(candidates, key=lambda n: self.get_node_conflicts(n, new_S))\n",
    "                        new_S.append(add)\n",
    "\n",
    "            new_conf = sum(self.get_node_conflicts(new_S[j], new_S[j+1:]) for j in range(len(new_S)))\n",
    "            delta = (new_conf * penalty - len(new_S)) - (current_conflicts * penalty - len(S))\n",
    "            if delta < 0 or random.random() < math.exp(-delta / T):\n",
    "                S, current_conflicts = new_S, new_conf\n",
    "            \n",
    "            if current_conflicts == 0: local_best = max(local_best, len(S))\n",
    "            T *= alpha\n",
    "            if T < 0.02: break\n",
    "        return False, local_best, None\n",
    "\n",
    "    def execute_global_run(self, target):\n",
    "        \"\"\"Runs attempts until success. This matches your 'Original Run'.\"\"\"\n",
    "        start = time.time()\n",
    "        attempts = 0\n",
    "        while True:\n",
    "            attempts += 1\n",
    "            success, best, clique = self.solve_attempt(target, 40000)\n",
    "            if success:\n",
    "                return time.time() - start, attempts, clique\n",
    "\n",
    "    def run_batch(self, num_samples=10, target=12):\n",
    "        print(f\"--- BATCH EVALUATION: {num_samples} FULL SUCCESSES ---\")\n",
    "        times, attempt_counts = [], []\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            duration, atts, _ = self.execute_global_run(target)\n",
    "            times.append(duration)\n",
    "            attempt_counts.append(atts)\n",
    "            print(f\"Sample {i+1}: Found in {duration:.2f}s ({atts} attempts)\")\n",
    "            \n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(\"BROCK PERFORMANCE SUMMARY\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"Avg Time to Success: {statistics.mean(times):.2f}s\")\n",
    "        print(f\"Avg Attempts Required: {statistics.mean(attempt_counts):.1f}\")\n",
    "        print(f\"Reliability (Success per attempt): {(1/statistics.mean(attempt_counts))*100:.2f}%\")\n",
    "        print(\"=\"*40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tester = BrockBatchRefined('brock200_2_nam.data')\n",
    "    # Use 10 samples instead of 100 because Brock takes ~120s per success\n",
    "    tester.run_batch(num_samples=10, target=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0315d6c-a7a5-45e1-84c1-aaf72b2ffda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ENHANCED BATCH: 5 SUCCESSES (SOFT BIAS) ---\n",
      "Sample 1: Found in 152.49s (12 attempts)\n",
      "Sample 2: Found in 505.28s (39 attempts)\n",
      "Sample 3: Found in 888.44s (74 attempts)\n",
      "Sample 4: Found in 281.31s (24 attempts)\n",
      "Sample 5: Found in 160.84s (14 attempts)\n",
      "\n",
      "========================================\n",
      "BROCK OPTIMIZED PERFORMANCE SUMMARY\n",
      "========================================\n",
      "Avg Time to Success: 397.67s\n",
      "Avg Attempts Required: 32.6\n",
      "Reliability (Prob per attempt): 3.07%\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from collections import deque\n",
    "import networkx as nx\n",
    "import statistics\n",
    "\n",
    "class BrockOptimizedBatch:\n",
    "    def __init__(self, nam_file):\n",
    "        with open(nam_file, 'rb') as f:\n",
    "            self.codes_int = pickle.load(f)\n",
    "        self.num_nodes = len(self.codes_int) - 1\n",
    "        \n",
    "        # 1. PageRank with Soft Bias (Optimized for Brock)\n",
    "        G = nx.Graph()\n",
    "        for u in range(1, self.num_nodes + 1):\n",
    "            for v in range(u + 1, self.num_nodes + 1):\n",
    "                if ((self.codes_int[u] >> v) & 1) == 0:\n",
    "                    G.add_edge(u, v)\n",
    "        \n",
    "        pr_scores = nx.pagerank(G, alpha=0.85)\n",
    "        self.nodes_list = list(range(1, self.num_nodes + 1))\n",
    "        # Use 1.2 instead of 3.0 to include 'spectral outliers' in the clique\n",
    "        self.weights = [pr_scores.get(i, 0)**1.2 for i in self.nodes_list]\n",
    "\n",
    "    def are_neighbors(self, u, v):\n",
    "        return ((self.codes_int[u] >> v) & 1) == 0\n",
    "\n",
    "    def get_node_conflicts(self, node, S):\n",
    "        return sum(1 for member in S if not self.are_neighbors(node, member))\n",
    "\n",
    "    def solve_attempt(self, target, max_steps):\n",
    "        # Start with a biased random node\n",
    "        S = random.choices(self.nodes_list, weights=self.weights, k=1)\n",
    "        tabu = deque(maxlen=80) # Increased to force exploration\n",
    "        T, alpha = 2.5, 0.99992 # Refined cooling schedule\n",
    "        current_conflicts = 0\n",
    "        \n",
    "        for i in range(max_steps):\n",
    "            # Strategic Oscillation\n",
    "            penalty = 25.0 if (i // 1000) % 2 == 0 else 3.5\n",
    "            \n",
    "            # Close-out scan (One-node-to-victory check)\n",
    "            if len(S) >= target - 1 and current_conflicts == 0:\n",
    "                for candidate in self.nodes_list:\n",
    "                    if candidate not in S and self.get_node_conflicts(candidate, S) == 0:\n",
    "                        S.append(candidate)\n",
    "                        if len(S) >= target: return True, S\n",
    "\n",
    "            new_S = list(S)\n",
    "            move = random.random()\n",
    "\n",
    "            if move < 0.15 and len(new_S) > 0: # Removal\n",
    "                node = random.choice(new_S)\n",
    "                new_S.remove(node)\n",
    "                tabu.append(node)\n",
    "            elif move < 0.60: # Expansion\n",
    "                potential = random.choices(self.nodes_list, weights=self.weights, k=60)\n",
    "                candidates = [n for n in potential if n not in tabu and n not in new_S]\n",
    "                if candidates:\n",
    "                    best_cand = min(candidates, key=lambda n: self.get_node_conflicts(n, new_S))\n",
    "                    new_S.append(best_cand)\n",
    "            else: # Swap\n",
    "                if len(new_S) > 0:\n",
    "                    rem = random.choice(new_S)\n",
    "                    new_S.remove(rem)\n",
    "                    tabu.append(rem)\n",
    "                    potential = random.choices(self.nodes_list, weights=self.weights, k=60)\n",
    "                    candidates = [n for n in potential if n not in tabu and n not in new_S]\n",
    "                    if candidates:\n",
    "                        add = min(candidates, key=lambda n: self.get_node_conflicts(n, new_S))\n",
    "                        new_S.append(add)\n",
    "\n",
    "            new_conf = sum(self.get_node_conflicts(new_S[j], new_S[j+1:]) for j in range(len(new_S)))\n",
    "            delta = (new_conf * penalty - len(new_S)) - (current_conflicts * penalty - len(S))\n",
    "            \n",
    "            if delta < 0 or (T > 0 and random.random() < math.exp(-delta / T)):\n",
    "                S, current_conflicts = new_S, new_conf\n",
    "            \n",
    "            T *= alpha\n",
    "            if T < 0.01: break\n",
    "        return False, None\n",
    "\n",
    "    def execute_global_run(self, target):\n",
    "        start = time.time()\n",
    "        attempts = 0\n",
    "        while True:\n",
    "            attempts += 1\n",
    "            success, clique = self.solve_attempt(target, 35000) # Slightly faster per attempt\n",
    "            if success:\n",
    "                return time.time() - start, attempts, clique\n",
    "\n",
    "    def run_batch(self, num_samples=5, target=12):\n",
    "        print(f\"--- ENHANCED BATCH: {num_samples} SUCCESSES (SOFT BIAS) ---\")\n",
    "        times, attempt_counts = [], []\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            duration, atts, _ = self.execute_global_run(target)\n",
    "            times.append(duration)\n",
    "            attempt_counts.append(atts)\n",
    "            print(f\"Sample {i+1}: Found in {duration:.2f}s ({atts} attempts)\")\n",
    "            \n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(\"BROCK OPTIMIZED PERFORMANCE SUMMARY\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"Avg Time to Success: {statistics.mean(times):.2f}s\")\n",
    "        print(f\"Avg Attempts Required: {statistics.mean(attempt_counts):.1f}\")\n",
    "        print(f\"Reliability (Prob per attempt): {(1/statistics.mean(attempt_counts))*100:.2f}%\")\n",
    "        print(\"=\"*40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tester = BrockOptimizedBatch('brock200_2_nam.data')\n",
    "    tester.run_batch(num_samples=5, target=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee3f6ab-14b6-4b56-bc9e-d72dd23e4484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
